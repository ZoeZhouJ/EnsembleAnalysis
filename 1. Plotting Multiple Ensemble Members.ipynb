{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbc0ae6-f854-4a84-97a9-db397df90940",
   "metadata": {},
   "source": [
    "# Plotting Time Series from Multiple Ensemble Members\n",
    "### Authors\n",
    "\n",
    "Samantha Stevenson sstevenson@ucsb.edu\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[Goals](#purpose)\n",
    "\n",
    "[Import Packages](#path)\n",
    "\n",
    "[Load and Query the CMIP6 AWS Catalog](#load)\n",
    "\n",
    "[Read in Data as an Xarray Object](#xarray)\n",
    "\n",
    "[Define a Region Using Shapefiles](#shapefiles)\n",
    "\n",
    "[Plot Time Series](#time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee4ee93-4107-43b1-af9b-34679f5326c2",
   "metadata": {},
   "source": [
    "<a id='purpose'></a> \n",
    "## **Goals**\n",
    "\n",
    "In this tutorial, we will be reading in the database of Coupled Model Intercomparison Project phase 6 (CMIP6) output hosted by Amazon Web Services and exploring its contents. \n",
    "\n",
    "The steps in this tutorial build on the skills we learned in previous tutorials:\n",
    "- [Read in Data and Plot a Time Series](https://github.com/climate-datalab/Time-Series-Plots/blob/main/1.%20Read%20in%20Climate%20Data%20%2B%20Plot%20a%20Regionally%20Averaged%20Time%20Series.ipynb)\n",
    "  (regional averaging, time series plotting)\n",
    "- [Opening and Querying the CMIP6 AWS Database](https://github.com/climate-datalab/CMIP6_AWS/blob/main/1.%20Opening%20and%20Querying%20the%20CMIP6%20Catalog.ipynb)  (data access via Amazon Web Services)\n",
    "\n",
    "Basically: we'll be doing a lot of the same things we did in those tutorials, but this time extending the plots to include information from multiple _ensemble members_ and multiple climate models! Please refer back to those materials if you would like additional detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79343f0-0d74-4661-a6ce-fb8ebeaadf00",
   "metadata": {},
   "source": [
    "<a id='path'></a> \n",
    "## **Import Packages**\n",
    "\n",
    "As always, we begin by importing the necessary packages for our analysis. This tutorial assumes you're starting with an environment in which `intake`, `intake-esm`, and `s3fs` are already installed - for details on those packages, see the [CMIP6 AWS repo](https://github.com/climate-datalab/CMIP6_AWS)!\n",
    "\n",
    "We'll also need a new package for this tutorial: `geopandas`. [Geopandas](https://geopandas.org/en/stable/index.html) is designed to facilitate working with geospatial data in Python; it layers the functionality of Pandas with the shape-handing abilities of Shapely to allow users to perform operations on geometrics objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300e5eef-47db-492a-98d6-299411c8689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import intake\n",
    "import s3fs\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2959485-3a89-48fa-941e-6f7eae8c53dd",
   "metadata": {},
   "source": [
    "<a id='load'></a> \n",
    "## **Load and Query the CMIP6 AWS Catalog**\n",
    "\n",
    "As we did in previous tutorials, we'll load the CMIP6 database hosted by Amazon Web Services. More detail on that database is available on the [Amazon Registry of Open Data](https://registry.opendata.aws/cmip6/).\n",
    "\n",
    "\n",
    "We first begin with opening the data catalog itself (_note - this step can be fairly slow on some machines_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32425dae-5bca-483b-bf55-8145f576a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CMIP6 data catalog, store as a variable\n",
    "catalog = intake.open_esm_datastore('https://cmip6-pds.s3.amazonaws.com/pangeo-cmip6.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b761086-cce3-47ba-ae44-dd4682d54564",
   "metadata": {},
   "source": [
    "Now, let's do some more sophisticated analysis! Rather than pulling down information from a single simulation, we'll aim to gather all of the _ensemble members_ for two different climate models. \n",
    "\n",
    "#### **What is an ensemble member??**\n",
    "\n",
    "This is a term we've thrown around in a couple of tutorials now - let's dig in and think about it a little more!\n",
    "\n",
    "The broad definition of an ensemble member is: **a single simulation run with a given climate model, for a given configuration**, where \"configuration\" here means that you've set the model up in a particular way (for instance: to run a simulation of the historical period, or for a specific future scenario). The _difference between ensemble members is ONLY that they have slightly different INITIAL CONDITIONS_ - everything else is the same!\n",
    "\n",
    "Let's display data from a couple of members of a single ensemble, to get a better idea of how that works. We'll start with picking a model, the Community Earth System Model version 2 (CESM2) - let's begin with the historical information, to make things simpler.\n",
    "\n",
    "Set the following fields to extract this information from the CMIP6 catalog:\n",
    "\n",
    "- **activity_id**: here we want \"CMIP\" since that's where the historical simulations live\n",
    "\n",
    "- **source_id**: this is the name of the model, so \"CESM2\"\n",
    "\n",
    "- **experiment_id**: the type of simulation we want, here \"historical\"\n",
    "\n",
    "- **table_id**: the category of output variable we're looking for. For surface air temperature, this will be in the atmosphere, and we'll pull out monthly data to make the files smaller: that means the \"Amon\" table is what we want!\n",
    "\n",
    "- **variable_id**: the actual name of the variable, here \"tas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c2d00a-ddc2-4c7f-a339-f4c48d444dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify search terms to query catalog \n",
    "# activity_id: which project do you want? CMIP = historical data\n",
    "activity_ids = ['CMIP'] \n",
    "\n",
    "# source_id: which model do you want? Let's say CESM2\n",
    "source_id = ['CESM2']\n",
    "\n",
    "# experiment_id: what experimental configuration do you want? Here we want historical and the four main SSPs\n",
    "experiment_ids = ['historical']\n",
    "\n",
    "# table_id: which part of the Earth system and time resolution do you want? Here we want monthly atmosphere data\n",
    "table_id = 'Amon' \n",
    "\n",
    "# variable_id: which climate variable do you want? Here we want surface air temperature\n",
    "variable_id = 'tas' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73df983-7f49-44c8-af96-06c57a5e8f65",
   "metadata": {},
   "source": [
    "As we did in tutorial 1, we now apply the `.search` functionality to retrieve the information we want, then convert it to a data frame that we can work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db42431-e741-4ecd-9d6a-6813feba3445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>zstore</th>\n",
       "      <th>dcpp_init_year</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r4i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r6i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r3i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r2i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r5i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r9i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r8i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r7i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r10i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r11i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_id institution_id source_id experiment_id  member_id table_id  \\\n",
       "0         CMIP           NCAR     CESM2    historical   r4i1p1f1     Amon   \n",
       "1         CMIP           NCAR     CESM2    historical   r6i1p1f1     Amon   \n",
       "2         CMIP           NCAR     CESM2    historical   r3i1p1f1     Amon   \n",
       "3         CMIP           NCAR     CESM2    historical   r1i1p1f1     Amon   \n",
       "4         CMIP           NCAR     CESM2    historical   r2i1p1f1     Amon   \n",
       "5         CMIP           NCAR     CESM2    historical   r5i1p1f1     Amon   \n",
       "6         CMIP           NCAR     CESM2    historical   r9i1p1f1     Amon   \n",
       "7         CMIP           NCAR     CESM2    historical   r8i1p1f1     Amon   \n",
       "8         CMIP           NCAR     CESM2    historical   r7i1p1f1     Amon   \n",
       "9         CMIP           NCAR     CESM2    historical  r10i1p1f1     Amon   \n",
       "10        CMIP           NCAR     CESM2    historical  r11i1p1f1     Amon   \n",
       "\n",
       "   variable_id grid_label                                             zstore  \\\n",
       "0          tas         gn  s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...   \n",
       "1          tas         gn  s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...   \n",
       "2          tas         gn  s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...   \n",
       "3          tas         gn  s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...   \n",
       "4          tas         gn  s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...   \n",
       "5          tas         gn  s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...   \n",
       "6          tas         gn  s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...   \n",
       "7          tas         gn  s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...   \n",
       "8          tas         gn  s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...   \n",
       "9          tas         gn  s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...   \n",
       "10         tas         gn  s3://cmip6-pds/CMIP6/CMIP/NCAR/CESM2/historica...   \n",
       "\n",
       "    dcpp_init_year   version  \n",
       "0              NaN  20190308  \n",
       "1              NaN  20190308  \n",
       "2              NaN  20190308  \n",
       "3              NaN  20190308  \n",
       "4              NaN  20190308  \n",
       "5              NaN  20190308  \n",
       "6              NaN  20190311  \n",
       "7              NaN  20190311  \n",
       "8              NaN  20190311  \n",
       "9              NaN  20190313  \n",
       "10             NaN  20190514  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search through catalog, store results in \"res\" variable\n",
    "res = catalog.search(activity_id=activity_ids, source_id=source_id, experiment_id=experiment_ids, \n",
    "                     table_id=table_id, variable_id=variable_id)\n",
    "\n",
    "# Display data frame associated with results\n",
    "display(res.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b9e07f-4b42-469d-8b8d-16074854ca07",
   "metadata": {},
   "source": [
    "Looking at the data frame displayed above, you might notice a couple of things. First: a lot of the entries seem nearly identical! That's good - after all, we're trying to get data from a SINGLE experiment with a SINGLE model.\n",
    "\n",
    "The entries that show up as DIFFERENT between the data frame rows above are:\n",
    "\n",
    "- **member_id**: this is where the names of the different ensemble members are stored. They will be things like \"r10i1p1f1\", \"r16i1p1f1\", etc. For more detail on how the member names work, you can refer back to the [Climate DataLab filename decoder](https://climate-datalab.org/filename-decoder/).\n",
    "\n",
    "- **zstore**: this is the location of a given ensemble member on the remote server (in this case, Amazon Web Services cloud hosting). This is what you'll need to refer to in order to load the data into local memory as an xarray object!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18182589-ce1b-4d5c-bd27-4abdef76b593",
   "metadata": {},
   "source": [
    "<a id='xarray'></a> \n",
    "## **Read in Data as an Xarray Object**\n",
    "\n",
    "Now we can read in the zarr stores containing the actual information. I'm going to do this in a few steps, which might seem a bit complicated at first but will make it easier to work with the data once it's read in!\n",
    "\n",
    "\n",
    "**1) Define an empty list**\n",
    "\n",
    "First, we define an empty object that can be used to store the set of data from all of our ensemble members.\n",
    "\n",
    "**2) Loop over all entries in the data frame**\n",
    "\n",
    "Now we loop over all the entries in the data frame, so that we can read each of these in as individual xarray objects. Here I have retrieved the total number of entries first, using the `.shape` command applied to the data frame: the dimension of the data frame is \\[number of data entries\\] x \\[number of data columns\\], so we want the first value output by `.shape`. \n",
    "\n",
    "To get the loop to step through the data frame, I use the `range` command: this creates a range of integers starting with 0 and ending with one less than the value you give it. So `range(10)` will give you the integers from 0 to 9, and so on.\n",
    "\n",
    "**3) Store data from each entry as xarray, add to list**\n",
    "\n",
    "Inside the loop, we next use `xr.open_zarr` to read in each individual entry as an xarray object. Note that we again have to specify that anonymous access is allowed using the syntax `storage_options={'anon': True}`. Each xarray object is then appended to the empty list we initialized before the loop began - now we have a list of xarray Datasets!\n",
    "\n",
    "**4) Concatenate the list into a single xarray object**\n",
    "\n",
    "After the loop finishes, we can convert the list of xarray Datasets into a new Dataset with an additional dimension, for which we can specify a new name. This is done via the xarray `.concat` method; I like to call the dimension \"member\" since it refers to ensemble members.\n",
    "\n",
    "As a nice bonus, we can also store the names of the actual ensemble members as value of the new \"member\" coordinate - that way we can keep track of that information in case we need it later. This is done using the `.assign_coords` function within xarray!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ba196a-91f3-489a-a203-68246e31f2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r4i1p1f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samstevenson/opt/anaconda3/lib/python3.8/site-packages/fsspec/registry.py:279: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r6i1p1f1\n",
      "r3i1p1f1\n",
      "r1i1p1f1\n",
      "r2i1p1f1\n",
      "r5i1p1f1\n",
      "r9i1p1f1\n",
      "r8i1p1f1\n",
      "r7i1p1f1\n",
      "r10i1p1f1\n",
      "r11i1p1f1\n"
     ]
    }
   ],
   "source": [
    "# Define an empty list\n",
    "ens_data = []\n",
    "\n",
    "# Retrieve number of entries in the data frame\n",
    "num = res.df.shape[0]\n",
    "\n",
    "# Loop over all entries in the data frame\n",
    "for mem in range(num):\n",
    "    print(res.df.member_id[mem])\n",
    "    # Store data from each entry as xarray, add to list\n",
    "    temp_data = xr.open_zarr(res.df['zstore'][mem], storage_options={'anon': True})\n",
    "    ens_data.append(temp_data)\n",
    "\n",
    "# Concatenate the list into a single xarray object\n",
    "ens_data = xr.concat(ens_data, dim=\"member\")\n",
    "\n",
    "# Store the actual member information as values of the new dimension\n",
    "ens_data = ens_data.assign_coords(member=(\"member\", res.df.member_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc62f11-b8f9-43d2-b408-74f28e805466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (lat: 192, member: 11, nbnd: 2, lon: 288, time: 1980)\n",
      "Coordinates:\n",
      "  * lat        (lat) float64 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "    lat_bnds   (member, lat, nbnd) float64 dask.array<chunksize=(1, 192, 2), meta=np.ndarray>\n",
      "  * lon        (lon) float64 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "    lon_bnds   (lon, nbnd) float32 -0.625 0.625 0.625 ... 358.1 358.1 359.4\n",
      "  * time       (time) object 1850-01-15 12:00:00 ... 2014-12-15 12:00:00\n",
      "    time_bnds  (time, nbnd) object 1850-01-01 00:00:00 ... 2015-01-01 00:00:00\n",
      "  * member     (member) object 'r4i1p1f1' 'r6i1p1f1' ... 'r10i1p1f1' 'r11i1p1f1'\n",
      "Dimensions without coordinates: nbnd\n",
      "Data variables:\n",
      "    tas        (member, time, lat, lon) float32 dask.array<chunksize=(1, 600, 192, 288), meta=np.ndarray>\n",
      "Attributes: (12/48)\n",
      "    Conventions:            CF-1.7 CMIP-6.2\n",
      "    activity_id:            CMIP\n",
      "    branch_method:          standard\n",
      "    branch_time_in_child:   674885.0\n",
      "    branch_time_in_parent:  182500.0\n",
      "    case_id:                18\n",
      "    ...                     ...\n",
      "    variable_id:            tas\n",
      "    variant_info:           CMIP6 20th century experiments (1850-2014) with C...\n",
      "    variant_label:          r4i1p1f1\n",
      "    status:                 2019-10-25;created;by nhn2@columbia.edu\n",
      "    netcdf_tracking_ids:    hdl:21.14100/ef376c2e-c83b-4e73-a770-010e28bb1776\n",
      "    version_id:             v20190308\n"
     ]
    }
   ],
   "source": [
    "# Look at the new dataset we've created\n",
    "print(ens_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c28a61-0806-4a46-bd98-605fbb17336b",
   "metadata": {},
   "source": [
    "<a id='shapefiles'></a> \n",
    "## **Define a Region Using Shapefiles**\n",
    "\n",
    "Now that the data have been read in, we can use it to plot a time series. In previous tutorials, we had been specifying lat/lon ranges using a rectangular box: but we can do better now! A common desire in analyzing geospatial data is to select regions with irregular boundaries - this is often done using shapefiles which specify the lat/lon coordinates of the boundary around a given region. \n",
    "\n",
    "There are many sources of shapefiles around the Internet: here we'll work with the [California Geographic Boundaries](https://catalog.data.gov/dataset/ca-geographic-boundaries) datasets. These contain information for state, county, and local place boundaries - to make sure we have a large enough region, let's use the state boundary. \n",
    "\n",
    "The shape file for the California state boundary was downloaded from the link above and is stored in this repo! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdc4154-f284-42f9-bc4f-43044b1c2a95",
   "metadata": {},
   "outputs": [
    {
     "ename": "CRSError",
     "evalue": "Invalid projection: EPSG:4326: (Internal Proj Error: proj_create: SQLite error on SELECT name, type, coordinate_system_auth_name, coordinate_system_code, datum_auth_name, datum_code, area_of_use_auth_name, area_of_use_code, text_definition, deprecated FROM geodetic_crs WHERE auth_name = ? AND code = ?: no such column: area_of_use_auth_name)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCRSError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t9/dmz5cq015_70jj_j3wryzp480000gn/T/ipykernel_95978/1931007592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ca_state/CA_State.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EPSG:4326'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Reproject to match Cartopy plotting projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#gdf = gdf.to_crs(epsg=4326)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, attr, val)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_geometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5586\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5587\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5588\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5589\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5590\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36mcrs\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"crs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/geopandas/array.py\u001b[0m in \u001b[0;36mcrs\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;34m\"\"\"Sets the value of the crs\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mCRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_user_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_geographic_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py\u001b[0m in \u001b[0;36mfrom_user_input\u001b[0;34m(value, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCRS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCRS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_geod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGeod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, projparams, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mprojstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpyproj/_crs.pyx\u001b[0m in \u001b[0;36mpyproj._crs._CRS.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCRSError\u001b[0m: Invalid projection: EPSG:4326: (Internal Proj Error: proj_create: SQLite error on SELECT name, type, coordinate_system_auth_name, coordinate_system_code, datum_auth_name, datum_code, area_of_use_auth_name, area_of_use_code, text_definition, deprecated FROM geodetic_crs WHERE auth_name = ? AND code = ?: no such column: area_of_use_auth_name)"
     ]
    }
   ],
   "source": [
    "# Read in shapefile for CA counties\n",
    "gdf = gpd.read_file('ca_state/CA_State.shp')\n",
    "\n",
    "gdf.crs = 'EPSG:4326'\n",
    "# Reproject to match Cartopy plotting projection\n",
    "#gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# This can be converted into a `proj4` string/dict compatible with GeoPandas\n",
    "crs_proj4 = proj.proj4_init\n",
    "gdf_cp = gdf.to_crs(crs_proj4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ca022-36e2-492e-ae26-26961249535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate historical and future projection data\n",
    "canesm5_data = xr.concat([hist_data, ssp370_data], dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cfad44-42ae-4964-a0a7-afd92ce5749f",
   "metadata": {},
   "source": [
    "Recall that the CanESM5 uses a non-standard 365-day year (no leap years), and to get the plotting to work correctly we have to convert the time format to `datetime64`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec4a57-1677-42a3-9cbd-b07efa788c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time to datetime64 format\n",
    "time = canesm5_data.time.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341a968-c1af-4596-8adf-2670b36973a8",
   "metadata": {},
   "source": [
    "Now we follow the rest of the steps from the previous tutorial to define lat/lon bounds, mask the data, and compute a regional average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f223154b-3638-4745-b3a3-51a6c42f8e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define min/max bounds for region of interest (NYC)\n",
    "lat_min, lat_max = 40, 41.5\n",
    "lon_min, lon_max = 285.5, 287\n",
    "\n",
    "# Define logical mask: True when lat/lon inside the valid ranges, False elsewhere\n",
    "tas_NYC_lat = (canesm5_data.lat >= lat_min) & (canesm5_data.lat <= lat_max)\n",
    "tas_NYC_lon = (canesm5_data.lon >= lon_min) & (canesm5_data.lon <= lon_max)\n",
    "\n",
    "# Find points where the mask value is True, drop all other points\n",
    "tas_NYC = canesm5_data.where(tas_NYC_lat & tas_NYC_lon, drop=True)\n",
    "\n",
    "# Average over lat, lon dimensions to get a time series\n",
    "tas_NYC = tas_NYC.mean(dim=[\"lat\", \"lon\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfe9310-8c29-4580-87a0-8adc05c4b4d4",
   "metadata": {},
   "source": [
    "and finally, generate our plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d08cea7-856c-4685-9190-faa5eff34f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "ax.plot(time, tas_NYC.tas, label='Near-Surface Air Temperature', color='b')\n",
    "ax.set_title(\"Time Series of NYC Near-Surface Air Temperature (1850 to 2100) \", fontsize=20)\n",
    "ax.set_xlabel(\"Time\", fontsize=20)\n",
    "ax.set_ylabel(\"Temperature (K)\", fontsize=20)\n",
    "ax.legend(fontsize=20)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f6e73-713f-4a8a-8eaf-789f564cee3c",
   "metadata": {},
   "source": [
    "Yay! Now you can compare this plot to the one you generated in the original tutorial, and see what they look like (hint: the historical portions should be the same!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb75b7-1819-4969-9f8e-18b2cebb7bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
