{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11c1f4d0-60ad-42b2-9a7d-bfafc254fde2",
   "metadata": {},
   "source": [
    "# Plotting Time Series from Multiple Ensemble Members\n",
    "## (using Regions Defined by Shape Files!)\n",
    "### Authors\n",
    "\n",
    "Samantha Stevenson sstevenson@ucsb.edu\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[Goals](#purpose)\n",
    "\n",
    "[Import Packages](#path)\n",
    "\n",
    "[Load and Query the CMIP6 AWS Catalog](#load)\n",
    "\n",
    "[Read in Data as an Xarray Object](#xarray)\n",
    "\n",
    "[Define a Region Using Shapefiles](#shapefiles)\n",
    "\n",
    "[Plot Time Series](#time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e5e3f-d7ff-4429-a986-348efdc2f005",
   "metadata": {},
   "source": [
    "<a id='purpose'></a> \n",
    "## **Goals**\n",
    "\n",
    "In this tutorial, we will be reading in the database of Coupled Model Intercomparison Project phase 6 (CMIP6) output hosted by Amazon Web Services and exploring its contents. \n",
    "\n",
    "The steps in this tutorial build on the skills we learned in previous tutorials:\n",
    "- [Read in Data and Plot a Time Series](https://github.com/climate-datalab/Time-Series-Plots/blob/main/1.%20Read%20in%20Climate%20Data%20%2B%20Plot%20a%20Regionally%20Averaged%20Time%20Series.ipynb)\n",
    "  (regional averaging, time series plotting)\n",
    "- [Opening and Querying the CMIP6 AWS Database](https://github.com/climate-datalab/CMIP6_AWS/blob/main/1.%20Opening%20and%20Querying%20the%20CMIP6%20Catalog.ipynb)  (data access via Amazon Web Services)\n",
    "\n",
    "Basically: we'll be doing a lot of the same things we did in those tutorials, but this time extending the plots to include information from multiple _ensemble members_ and multiple climate models! Please refer back to those materials if you would like additional detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13901a3c-886b-46be-9142-985e660a00fe",
   "metadata": {},
   "source": [
    "<a id='path'></a> \n",
    "## **Import Packages**\n",
    "\n",
    "As always, we begin by importing the necessary packages for our analysis. This tutorial assumes you're starting with an environment in which `intake`, `intake-esm`, and `s3fs` are already installed - for details on those packages, see the [CMIP6 AWS repo](https://github.com/climate-datalab/CMIP6_AWS)!\n",
    "\n",
    "We'll also need a new package for this tutorial: `geopandas`. [Geopandas](https://geopandas.org/en/stable/index.html) is designed to facilitate working with geospatial data in Python; it layers the functionality of Pandas with the shape-handing abilities of Shapely to allow users to perform operations on geometrics objects. \n",
    "\n",
    "Last but not least: we'll also import the coordinate reference system handling functionality from Cartopy (`cartopy.crs`; for more details see the [Cartopy CRS docs page](https://scitools.org.uk/cartopy/docs/latest/getting_started/crs.html)). This will allow us to reproject geospatial data onto a given CRS using Geopandas later on! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ca01c-9b61-497e-b15e-d9453b6674ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import intake\n",
    "import s3fs\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef232f75-5bf9-4fb0-a3ff-c1bd14569a5e",
   "metadata": {},
   "source": [
    "<a id='shapefiles'></a> \n",
    "## **Define a Region Using Shapefiles**\n",
    "\n",
    "Now that the data have been read in, we can use it to plot a time series. In previous tutorials, we had been specifying lat/lon ranges using a rectangular box: but we can do better now! A common desire in analyzing geospatial data is to select regions with irregular boundaries - this is often done using shapefiles which specify the lat/lon coordinates of the boundary around a given region. \n",
    "\n",
    "There are many sources of shapefiles around the Internet: here we'll work with the [California Geographic Boundaries](https://catalog.data.gov/dataset/ca-geographic-boundaries) datasets. These contain information for state, county, and local place boundaries - to make sure we have a large enough region, let's use the state boundary. \n",
    "\n",
    "The shape file for the California state boundary was downloaded from the link above and is stored in this repo (see folder \"ca_state\"). It can be read in using the Geopandas `.read_file()` method!\n",
    "\n",
    "While we're at it, let's also reproject the file to use a specific coordinate reference system - in this case, the Plate Carree projection. This isn't strictly required since the shape file does contain a default CRS, but we _will_ need to make sure in a minute that our CRS is consistent between the shape file and the climate model data, so we might as well explicitly include a reprojection step just to make sure we don't forget to check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b47c0d-4015-4e60-8c95-82e27b469513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in shapefile for CA counties\n",
    "gdf = gpd.read_file('ca_state/CA_State.shp')\n",
    "\n",
    "# Look at default CRS for the shape file\n",
    "print(gdf.crs)\n",
    "\n",
    "# Reproject the shapefile to use the PlateCarree projection\n",
    "gdf = gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dcc922-4b43-46ee-987a-f83ab34378d3",
   "metadata": {},
   "source": [
    "Now that we have our shape file, the next task is to take the lat and lon coordinates from the climate model grid, and figure out which of those points lie within the boundaries of the shape (in this case, the California state borders). This requires a couple of steps:\n",
    "\n",
    "- Converting the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964db7a6-54f0-439f-9591-7d78511721a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Make 2D lat, lon\n",
    "lon_vals = ens_data.lon.values\n",
    "lon_vals = np.where(lon_vals > 180, lon_vals - 360, lon_vals)\n",
    "\n",
    "lon2d, lat2d = np.meshgrid(lon_vals, ens_data.lat.values)\n",
    "\n",
    "# Create a GeoDataFrame from the xarray dataset's coordinates\n",
    "points = [Point(lon, lat) for lon, lat in zip(lon2d.flatten(), lat2d.flatten())]\n",
    "points_gdf = gpd.GeoDataFrame(geometry=points, crs=\"EPSG:4326\")\n",
    "\n",
    "# Print the points to see what they look like\n",
    "#print(points_gdf)\n",
    "\n",
    "# Spatial join to find points within the shapefile\n",
    "joined = gpd.sjoin(points_gdf, gdf, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "# Create a mask based on the spatial join\n",
    "mask = np.isin(np.arange(points_gdf.shape[0]), joined.index)\n",
    "mask_2d = mask.reshape(lat2d.shape)\n",
    "\n",
    "#masked_data = temp_data.where(mask_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9debb5-ca0b-45b2-ad14-ff5839af83dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere(mask_2d)\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13322d74-3aed-4e6b-a4a2-b26da6d5d7fd",
   "metadata": {},
   "source": [
    "In order to work with this shape file in combination with our climate model information, we need to define a _coordinate reference system (CRS)_ for both. This is essentially a framework for locating different spatial points on the surface of Earth; more information on coordinate reference systems can be found [here](https://www.earthdatascience.org/courses/earth-analytics/spatial-data-r/intro-to-coordinate-reference-systems/)\n",
    "\n",
    "The code block below defines our CRS using the [Plate Carree](https://pro.arcgis.com/en/pro-app/latest/help/mapping/properties/plate-carree.htm) projection, centered at a longitude of 180, and reprojects the data in the CA shape file to use the same projection. \n",
    "\n",
    "_Note: the `epsg=4326` syntax below is how you refer to the Plate Carree projection in the language of Geopandas! The [EPSG database](https://epsg.org/home.html) has numbered various projections/CRS, and 4326 is the one that corresponds to Plate Carree._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20009906-ade1-4ead-972f-13eb71efd327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject the shapefile to use the PlateCarree projection\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Make 2D lat, lon\n",
    "lon2d, lat2d = np.meshgrid(ens_data.lon.values, ens_data.lat.values)\n",
    "\n",
    "# Create a GeoDataFrame from the xarray dataset's coordinates\n",
    "points = [Point(lon, lat) for lon, lat in zip(lon2d.flatten(), lat2d.flatten())]\n",
    "points_gdf = gpd.GeoDataFrame(geometry=points, crs=\"EPSG:4326\")\n",
    "\n",
    "# Print the points to see what they look like\n",
    "print(points_gdf)\n",
    "\n",
    "# Spatial join to find points within the shapefile\n",
    "joined = gpd.sjoin(points_gdf, gdf, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "# Create a mask based on the spatial join\n",
    "mask = np.isin(np.arange(points_gdf.shape[0]), joined.index)\n",
    "mask_2d = mask.reshape(lat2d.shape)\n",
    "\n",
    "#masked_data = temp_data.where(mask_2d)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
